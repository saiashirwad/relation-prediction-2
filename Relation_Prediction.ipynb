{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Relation Prediction.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1oNre-UhqlqMdISfOhJxnnAha7sV7-93K",
      "authorship_tag": "ABX9TyNJd/WqFqna1sEE1JdOIixp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a41548288655467a8e061e05939ed482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48142073d9d34dbcbbf16742db6b022d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9d680ec8ef3b4ad8873b28a896155630",
              "IPY_MODEL_de5c2190f0dc4b8cbf46395b5431d95a"
            ]
          }
        },
        "48142073d9d34dbcbbf16742db6b022d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d680ec8ef3b4ad8873b28a896155630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_713a9d7231a447ca9612defc5606bdf8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f79198176744f168332df64fca6979b"
          }
        },
        "de5c2190f0dc4b8cbf46395b5431d95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f7a8ef2328644c3a46e7b802237a3cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:28&lt;00:00,  5.64s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_381390a6fade4603bfb973943a95bb46"
          }
        },
        "713a9d7231a447ca9612defc5606bdf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f79198176744f168332df64fca6979b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f7a8ef2328644c3a46e7b802237a3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "381390a6fade4603bfb973943a95bb46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saiashirwad/relation-prediction-2/blob/master/Relation_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60kgRpkWFYdu",
        "colab_type": "code",
        "outputId": "3f0e9ef3-f16a-4cba-eee6-126aad42476f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/Thesis/code/relation-prediction-2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Thesis/code/relation-prediction-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIaSYFx6bYC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23V6Qv2pVyke",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7yK9kZXErI1",
        "colab_type": "code",
        "outputId": "91e05a3f-5633-469f-a2ec-51918ea84e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rzKQzS-hQYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEp0O_G5cDL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from layers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPIyfYJWFV0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install torchkge --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l4r5emkFpjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLaiB3fEFrzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import * \n",
        "import torch \n",
        "import torch.nn as nn \n",
        "from functools import reduce \n",
        "from operator import mul \n",
        "from torch_scatter import scatter \n",
        "from sklearn.metrics.pairwise import pairwise_distances "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbkDVP8yGSs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from train import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4VmjZbpGGjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kg_train, kg_test, kg_val = load_fb15k237()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GluE6euGO8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = Args(100, 200, 100, 2, 100, 80000, 0.001, 10, 'cuda', 'sgd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s-BKWtsHZul",
        "colab_type": "code",
        "outputId": "aac0a094-7dd1-41f8-f2ae-0dcd82d8f613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_ent, n_rel = kg_train.n_ent, kg_train.n_rel\n",
        "total_triplets = get_valid_triplets(kg_train, kg_test, kg_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique triplets: 620232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baNBqi9E6u3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_func2(triplets, neg_sampling_ratio, ent_embed, rel_embed, device='cpu'):\n",
        "    \"\"\"\n",
        "    Triplets order: src, dst, rel\n",
        "    \"\"\"\n",
        "    n = len(triplets)\n",
        "    if type(triplets) == np.ndarray:\n",
        "        triplets = torch.from_numpy(triplets)\n",
        "\n",
        "    pos_triplets = triplets[:n // (neg_sampling_ratio + 1)]\n",
        "    pos_triplets = torch.cat([pos_triplets for _ in range(neg_sampling_ratio)])\n",
        "\n",
        "    neg_triplets = triplets[n // (neg_sampling_ratio + 1):]\n",
        "\n",
        "\n",
        "    src_embed_ = ent_embed[pos_triplets[:, 0]]\n",
        "    dst_embed_ = ent_embed[pos_triplets[:, 1]]\n",
        "    rel_embed_ = rel_embed[pos_triplets[:, 2]]\n",
        "\n",
        "    x = src_embed_ + rel_embed_ - dst_embed_\n",
        "    pos_norm = torch.norm(x, p=2, dim=1)\n",
        "\n",
        "\n",
        "    src_embed_ = ent_embed[neg_triplets[:, 0]]\n",
        "    dst_embed_ = ent_embed[neg_triplets[:, 1]]\n",
        "    rel_embed_ = rel_embed[neg_triplets[:, 2]]\n",
        "\n",
        "    x = src_embed_ + rel_embed_ - dst_embed_\n",
        "    neg_norm = torch.norm(x, p=2, dim=1)\n",
        "\n",
        "    y = torch.ones(len(pos_triplets)).to(device)\n",
        "\n",
        "    loss_fn = nn.MarginRankingLoss(margin=5)\n",
        "    loss = loss_fn(pos_norm, neg_norm, y)\n",
        "\n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLazSeLdHcHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader = DataLoader(kg_train, batch_size=args.batch_size, shuffle=False, pin_memory=cuda.is_available())\n",
        "ent_embed, rel_embed = get_init_embed()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn7Vm7jJUeJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNAFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, edge, edge_w, N, E, out_features):\n",
        "        a = torch.sparse_coo_tensor(\n",
        "            edge, edge_w, torch.Size([N, N, out_features]))\n",
        "        b = torch.sparse.sum(a, dim=1)\n",
        "        ctx.N = b.shape[0]\n",
        "        ctx.outfeat = b.shape[1]\n",
        "        ctx.E = E\n",
        "        ctx.indices = a._indices()[0, :]\n",
        "\n",
        "        return b.to_dense()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        grad_values = None\n",
        "        if ctx.needs_input_grad[1]:\n",
        "            edge_sources = ctx.indices\n",
        "\n",
        "            if(torch.cuda.is_available()):\n",
        "                edge_sources = edge_sources.cuda()\n",
        "\n",
        "            grad_values = grad_output[edge_sources]\n",
        "        return None, grad_values, None, None, None\n",
        "\n",
        "class SparseNeighborhoodAggregation(nn.Module):\n",
        "    def forward(self, edge, edge_w, N, E, out_features):\n",
        "        return SNAFunction.apply(edge, edge_w, N, E, out_features)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufNfvzGIUtSl",
        "colab_type": "text"
      },
      "source": [
        "![](https://i.imgur.com/2v9bxG1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTnD7H2CHd-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KGLayer(nn.Module):\n",
        "    def __init__(self, n_entities, n_relations, ent_embed, rel_embed, in_dim, out_dim, concat=True, device=\"cuda\"):\n",
        "        super(KGLayer, self).__init__()\n",
        "\n",
        "        self.n_entities = n_entities\n",
        "        self.n_relations = n_relations\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.device = device\n",
        "\n",
        "        self.a = nn.Linear(3 * in_dim, out_dim).to(device)\n",
        "        nn.init.xavier_normal_(self.a.weight.data, gain=1.414)\n",
        "\n",
        "        self.concat = concat\n",
        "\n",
        "        self.a_2 = nn.Linear(out_dim, 1).to(device)\n",
        "        nn.init.xavier_normal_(self.a_2.weight.data, gain=1.414)\n",
        "\n",
        "        self.sparse_neighborhood_aggregation = SparseNeighborhoodAggregation()\n",
        "\n",
        "        self.ent_embed = nn.Embedding(n_entities, in_dim).to(device)\n",
        "        self.rel_embed = nn.Embedding(n_relations, in_dim).to(device)\n",
        "        \n",
        "        # nn.init.xavier_normal_(self.ent_embed.weight.data, 1.414)\n",
        "        # nn.init.xavier_normal_(self.rel_embed.weight.data, 1.414)\n",
        "        \n",
        "        self.ent_embed.weight = nn.Parameter(ent_embed.to(\"cuda\"))\n",
        "        self.rel_embed.weight = nn.Parameter(rel_embed.to(\"cuda\"))\n",
        "    \n",
        "    def forward(self, triplets, eval=False):\n",
        "\n",
        "        N = self.n_entities\n",
        "\n",
        "        h = torch.cat((\n",
        "            self.ent_embed(triplets[:, 0]),\n",
        "            self.ent_embed(triplets[:, 1]),\n",
        "            self.rel_embed(triplets[:, 2])\n",
        "        ), dim=1)\n",
        "        c = self.a(h)\n",
        "        b = -F.leaky_relu(self.a_2(c))\n",
        "        e_b = torch.exp(b)\n",
        "\n",
        "        temp = triplets.t()\n",
        "        edges = torch.stack([temp[0], temp[1]])\n",
        "\n",
        "        ebs = self.sparse_neighborhood_aggregation(edges, e_b, N, e_b.shape[0], 1)\n",
        "        temp1 = e_b * c\n",
        "\n",
        "        hs = self.sparse_neighborhood_aggregation(edges, temp1,  N, e_b.shape[0], self.out_dim)\n",
        "\n",
        "        ebs[ebs == 0] = 1e-12\n",
        "\n",
        "\n",
        "        h_ent = hs / ebs\n",
        "\n",
        "        index = triplets[:, 2]\n",
        "        h_rel = scatter(temp1, index=index, dim=0, reduce=\"mean\")\n",
        "        \n",
        "        if self.concat:\n",
        "            return F.elu(h_ent), F.elu(h_rel)\n",
        "        else:\n",
        "            return h_ent, h_rel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b004hFk2Hhhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KGLayer(n_ent, n_rel, ent_embed, rel_embed, 100, 100, True, \"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jFJ8VF4HkH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = SGD(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKxQY7TwHlZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batches = [b for b in dataloader]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7vFP2GgHm8u",
        "colab_type": "code",
        "outputId": "a1aff6bc-304d-4f49-c599-e20cdffe3da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "a41548288655467a8e061e05939ed482",
            "48142073d9d34dbcbbf16742db6b022d",
            "9d680ec8ef3b4ad8873b28a896155630",
            "de5c2190f0dc4b8cbf46395b5431d95a",
            "713a9d7231a447ca9612defc5606bdf8",
            "7f79198176744f168332df64fca6979b",
            "0f7a8ef2328644c3a46e7b802237a3cf",
            "381390a6fade4603bfb973943a95bb46"
          ]
        }
      },
      "source": [
        "for epoch in tnrange(5):\n",
        "    losses = []\n",
        "    for i in range(len(batches)):\n",
        "        batch = batches[i]\n",
        "        triplets = torch.stack(batch)\n",
        "        triplets, labels, nodes, edges = negative_sampling(triplets, n_ent, args.negative_rate)\n",
        "        triplets, labels = triplets.to(args.device), labels.to(args.device)\n",
        "    \n",
        "        model.zero_grad()\n",
        "    \n",
        "        # start = time.time()\n",
        "        model.train()\n",
        "        ent_embed_, rel_embed_ = model(triplets)\n",
        "        loss = loss_func2(triplets, args.negative_rate, ent_embed_, rel_embed_, device=\"cuda\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        # del triplets\n",
        "        # del labels\n",
        "        # del ent_embed_\n",
        "        # del rel_embed_\n",
        "        # del nodes \n",
        "        # del edges  \n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "        losses.append(loss.item())\n",
        "        # print(loss.item())\n",
        "        # del loss \n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    # print(f\"epoch: {epoch}, loss: {sum(losses) / len(losses)}\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a41548288655467a8e061e05939ed482",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3nC541cH3Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), \"model.save\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrxC9XIpYGuh",
        "colab_type": "code",
        "outputId": "0c405889-eca0-47d6-8057-915fa95d6af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load(\"model.save\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMhxjrJiPlF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dl = DataLoader(kg_val, 10000, shuffle=True)\n",
        "data = [d for d in dl]\n",
        "triplets = data[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo7jojhbW5ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eval \n",
        "triplets = torch.stack(data[0])\n",
        "triplets, labels, nodes, edges = negative_sampling(triplets, n_ent, 0)\n",
        "triplets, labels = triplets.to(args.device), labels.to(args.device)\n",
        "model.eval() \n",
        "\n",
        "ee, re = model(triplets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YOyvBaodUEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ee = model.ent_embed.weight.cpu().detach()\n",
        "re = model.rel_embed.weight.cpu().detach() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_9HObonXNMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e = ee.cpu().detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmM9GSLjYfW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r = re.cpu().detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMLegcKZS8B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_ = [s.item() for s in triplets[:, 0]]\n",
        "dst_ = [d.item() for d in triplets[:, 1]]\n",
        "rel_ = [r.item() for r in triplets[:, 2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEx6XAIUTV_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src = e[src_]\n",
        "dst = e[dst_]\n",
        "rel = r[rel_]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ajvM7e0T8Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist = pairwise_distances(dst - rel, e, metric=\"euclidean\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blTqpvL-T-6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankArrayHead = np.argsort(dist, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpfIt-eVUAoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankListHead =  [int(np.argwhere(e[1] == e[0])) for e in zip(src_, rankArrayHead)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPgRkoksUDHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "isHit10Head = [x for x in rankListHead if x < 10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD_2hQzXULJ4",
        "colab_type": "code",
        "outputId": "19ec9479-9412-490b-ca01-89fec8bf3e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum(rankListHead) / len(rankListHead)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7254.7366"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsvnpJqdeUfI",
        "colab_type": "code",
        "outputId": "7ac0affa-c62b-4e66-ea70-ac0a3cc73db0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(isHit10Head)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIdTXsb6fBTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist2 = pairwise_distances(src + rel, e, metric=\"euclidean\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrmKgTfBf5Ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankArrayTail = np.argsort(dist2, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_8mtoO4f-5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankListTail = [int(np.argwhere(e[1] == e[0])) for e in zip(dst_, rankArrayTail)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPfbY9DhgILf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "isHit10Tail = [x for x in rankListTail if x < 10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy0vtKO2gQnp",
        "colab_type": "code",
        "outputId": "94733ee1-8621-4f6d-f3b0-b8487ebd6ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(isHit10Tail)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6PjkZvMgVvS",
        "colab_type": "code",
        "outputId": "042869b4-e6f1-49f8-eece-1185f267fdfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum(rankListTail) / len(rankListTail)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7202.4886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KOJgzzphDQi",
        "colab_type": "code",
        "outputId": "dd561a2b-2e9b-4937-8719-4dcad87e10df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 16 09:38:42 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0    71W / 149W |    661MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NKXgFTVh4eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}