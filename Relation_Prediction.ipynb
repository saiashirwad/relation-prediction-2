{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Relation Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1oNre-UhqlqMdISfOhJxnnAha7sV7-93K",
      "authorship_tag": "ABX9TyM0t7y9tgY7ybQptsXBh0Sq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d4901b70010492cb0b23006dcfdb02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ded625fd22394c3c8d5c22c2ea0a62c0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb477648fc5141439a010af5bb0474ed",
              "IPY_MODEL_3c8e7cb3cd014c909e045dc229da4477"
            ]
          }
        },
        "ded625fd22394c3c8d5c22c2ea0a62c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb477648fc5141439a010af5bb0474ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_572808bd7e684739a950defc3be837eb",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf446797fa544a5ea3fc42f4b98819bf"
          }
        },
        "3c8e7cb3cd014c909e045dc229da4477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6fcbddb113fd42359bb13abbb64191f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [01:01&lt;00:00, 12.36s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32ce44a56c5849b2862fad237a09ee5f"
          }
        },
        "572808bd7e684739a950defc3be837eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf446797fa544a5ea3fc42f4b98819bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fcbddb113fd42359bb13abbb64191f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32ce44a56c5849b2862fad237a09ee5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b925174d9145465e81e905c5f4758c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6cf37ea8c6c74acaa48595d4ed42ef3e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_43bb347146154eed98bb448ca7d7de38",
              "IPY_MODEL_d2cf6e5f0bdc4ae3bc7da7f26ba957f0"
            ]
          }
        },
        "6cf37ea8c6c74acaa48595d4ed42ef3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43bb347146154eed98bb448ca7d7de38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_977b5ee167b14adb8a0a44555103ad40",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5855a42937eb43c1986c8f1c9fee6277"
          }
        },
        "d2cf6e5f0bdc4ae3bc7da7f26ba957f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_590f80f42bd641ffb118fc27fe711633",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1000 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a20ec3ce32ea4a1fac3db08b77574627"
          }
        },
        "977b5ee167b14adb8a0a44555103ad40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5855a42937eb43c1986c8f1c9fee6277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "590f80f42bd641ffb118fc27fe711633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a20ec3ce32ea4a1fac3db08b77574627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saiashirwad/relation-prediction-2/blob/master/Relation_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60kgRpkWFYdu",
        "colab_type": "code",
        "outputId": "849e06ee-9345-4672-d0e6-d653e574a2a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/Thesis/code/relation-prediction-2"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Thesis/code/relation-prediction-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7yK9kZXErI1",
        "colab_type": "code",
        "outputId": "652b6ba7-89a6-42f7-c0a4-aad6bf88a810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rzKQzS-hQYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPIyfYJWFV0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install torchkge --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l4r5emkFpjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLaiB3fEFrzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import * \n",
        "import torch \n",
        "import torch.nn as nn \n",
        "from functools import reduce \n",
        "from operator import mul \n",
        "from torch_scatter import scatter \n",
        "from sklearn.metrics.pairwise import pairwise_distances "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0EjdShxlP12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbkDVP8yGSs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from train import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4VmjZbpGGjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kg_train, kg_test, kg_val = load_fb15k237()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GluE6euGO8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = Args(100, 200, 100, 2, 100, 20000, 0.001, 10, 'cuda', 'sgd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s-BKWtsHZul",
        "colab_type": "code",
        "outputId": "7f666ddc-ee6c-4c26-a9b6-3bd9e8009380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_ent, n_rel = kg_train.n_ent, kg_train.n_rel\n",
        "total_triplets = get_valid_triplets(kg_train, kg_test, kg_val)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique triplets: 620232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baNBqi9E6u3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_transe(triplets, neg_sampling_ratio, ent_embed, rel_embed, device='cpu'):\n",
        "    \"\"\"\n",
        "    Triplets order: src, dst, rel\n",
        "    \"\"\"\n",
        "    n = len(triplets)\n",
        "    if type(triplets) == np.ndarray:\n",
        "        triplets = torch.from_numpy(triplets)\n",
        "\n",
        "    pos_triplets = triplets[:n // (neg_sampling_ratio + 1)]\n",
        "    pos_triplets = torch.cat([pos_triplets for _ in range(neg_sampling_ratio)])\n",
        "\n",
        "    neg_triplets = triplets[n // (neg_sampling_ratio + 1):]\n",
        "\n",
        "\n",
        "    src_embed_ = ent_embed[pos_triplets[:, 0]]\n",
        "    dst_embed_ = ent_embed[pos_triplets[:, 1]]\n",
        "    rel_embed_ = rel_embed[pos_triplets[:, 2]]\n",
        "\n",
        "    x = src_embed_ + rel_embed_ - dst_embed_\n",
        "    pos_norm = torch.norm(x, p=2, dim=1)\n",
        "\n",
        "\n",
        "    src_embed_ = ent_embed[neg_triplets[:, 0]]\n",
        "    dst_embed_ = ent_embed[neg_triplets[:, 1]]\n",
        "    rel_embed_ = rel_embed[neg_triplets[:, 2]]\n",
        "\n",
        "    x = src_embed_ + rel_embed_ - dst_embed_\n",
        "    neg_norm = torch.norm(x, p=2, dim=1)\n",
        "\n",
        "    y = torch.ones(len(pos_triplets)).to(device)\n",
        "\n",
        "    loss_fn = nn.MarginRankingLoss(margin=5)\n",
        "    loss = loss_fn(pos_norm, neg_norm, y)\n",
        "\n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLazSeLdHcHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader = DataLoader(kg_train, batch_size=args.batch_size, shuffle=False, pin_memory=cuda.is_available())\n",
        "ent_embed, rel_embed = get_init_embed()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKxQY7TwHlZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batches = [b for b in dataloader]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn7Vm7jJUeJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNAFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, edge, edge_w, N, E, out_features):\n",
        "        a = torch.sparse_coo_tensor(\n",
        "            edge, edge_w, torch.Size([N, N, out_features]))\n",
        "        b = torch.sparse.sum(a, dim=1)\n",
        "        ctx.N = b.shape[0]\n",
        "        ctx.outfeat = b.shape[1]\n",
        "        ctx.E = E\n",
        "        ctx.indices = a._indices()[0, :]\n",
        "\n",
        "        return b.to_dense()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        grad_values = None\n",
        "        if ctx.needs_input_grad[1]:\n",
        "            edge_sources = ctx.indices\n",
        "\n",
        "            if(torch.cuda.is_available()):\n",
        "                edge_sources = edge_sources.cuda()\n",
        "\n",
        "            grad_values = grad_output[edge_sources]\n",
        "        return None, grad_values, None, None, None\n",
        "\n",
        "class SparseNeighborhoodAggregation(nn.Module):\n",
        "    def forward(self, edge, edge_w, N, E, out_features):\n",
        "        return SNAFunction.apply(edge, edge_w, N, E, out_features)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufNfvzGIUtSl",
        "colab_type": "text"
      },
      "source": [
        "![](https://i.imgur.com/2v9bxG1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTnD7H2CHd-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KGLayer(nn.Module):\n",
        "    def __init__(self, n_entities, n_relations, ent_embed, rel_embed, in_dim, out_dim, input_drop=0.5, concat=True, device=\"cuda\"):\n",
        "        super(KGLayer, self).__init__()\n",
        "\n",
        "        self.n_entities = n_entities\n",
        "        self.n_relations = n_relations\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.device = device\n",
        "\n",
        "        self.a = nn.Linear(3 * in_dim, out_dim).to(device)\n",
        "        nn.init.xavier_normal_(self.a.weight.data, gain=1.414)\n",
        "\n",
        "        self.concat = concat\n",
        "\n",
        "        self.a_2 = nn.Linear(out_dim, 1).to(device)\n",
        "        nn.init.xavier_normal_(self.a_2.weight.data, gain=1.414)\n",
        "\n",
        "        self.sparse_neighborhood_aggregation = SparseNeighborhoodAggregation()\n",
        "\n",
        "        self.ent_embed = nn.Embedding(n_entities, in_dim, max_norm=1, norm_type=2).to(device)\n",
        "        self.rel_embed = nn.Embedding(n_relations, in_dim, max_norm=1, norm_type=2).to(device)\n",
        "        \n",
        "        nn.init.xavier_normal_(self.ent_embed.weight.data, 1.414)\n",
        "        nn.init.xavier_normal_(self.rel_embed.weight.data, 1.414)\n",
        "        \n",
        "        # self.ent_embed.weight = nn.Parameter(ent_embed.to(\"cuda\"))\n",
        "        # self.rel_embed.weight = nn.Parameter(rel_embed.to(\"cuda\"))\n",
        "\n",
        "        self.input_drop = nn.Dropout(input_drop)\n",
        "\n",
        "        self.bn0 = nn.BatchNorm1d(3 * in_dim).to(device)\n",
        "        self.bn1 = nn.BatchNorm1d(out_dim).to(device)\n",
        "\n",
        "    \n",
        "    def forward(self, triplets):\n",
        "\n",
        "        N = self.n_entities\n",
        "\n",
        "        h = torch.cat((\n",
        "            self.ent_embed(triplets[:, 0]),\n",
        "            self.ent_embed(triplets[:, 1]),\n",
        "            self.rel_embed(triplets[:, 2])\n",
        "        ), dim=1)\n",
        "        h_ = torch.cat((\n",
        "            self.ent_embed(triplets[:, 1]),\n",
        "            self.ent_embed(triplets[:, 0]),\n",
        "           -self.rel_embed(triplets[:, 2])  \n",
        "        ), dim=1)\n",
        "        h = torch.cat((h, h_)) # should I check for the presence of t,h,r in triplets?\n",
        "\n",
        "        h = self.input_drop(self.bn0(h))\n",
        "        c = self.bn1(self.a(h))\n",
        "        b = -F.leaky_relu(self.a_2(c))\n",
        "        e_b = torch.exp(b)\n",
        "\n",
        "        temp = triplets.t()\n",
        "        edges = torch.stack((\n",
        "            torch.cat([temp[0], temp[1]]),\n",
        "            torch.cat([temp[1], temp[0]])\n",
        "        ))\n",
        "\n",
        "        ebs = self.sparse_neighborhood_aggregation(edges, e_b, N, e_b.shape[0], 1)\n",
        "        temp1 = e_b * c\n",
        "\n",
        "        hs = self.sparse_neighborhood_aggregation(edges, temp1,  N, e_b.shape[0], self.out_dim)\n",
        "\n",
        "        ebs[ebs == 0] = 1e-12\n",
        "        h_ent = hs / ebs\n",
        "\n",
        "        index = triplets[:, 2]\n",
        "        h_rel  = scatter(temp1[ : temp1.shape[0]//2, :], index=index, dim=0, reduce=\"mean\")\n",
        "        h_rel_ = scatter(temp1[temp1.shape[0]//2 : , :], index=index, dim=0, reduce=\"mean\")  \n",
        "\n",
        "        h_rel = h_rel - h_rel_  \n",
        "\n",
        "        if self.concat:\n",
        "            return F.elu(h_ent), F.elu(h_rel)\n",
        "        else:\n",
        "            return h_ent, h_rel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b004hFk2Hhhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KGLayer(n_ent, n_rel, ent_embed, rel_embed, 100, 100, 0.5, True, \"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jFJ8VF4HkH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = SGD(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7vFP2GgHm8u",
        "colab_type": "code",
        "outputId": "210dbdc1-492b-44f0-e388-99167070641b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "1d4901b70010492cb0b23006dcfdb02b",
            "ded625fd22394c3c8d5c22c2ea0a62c0",
            "fb477648fc5141439a010af5bb0474ed",
            "3c8e7cb3cd014c909e045dc229da4477",
            "572808bd7e684739a950defc3be837eb",
            "cf446797fa544a5ea3fc42f4b98819bf",
            "6fcbddb113fd42359bb13abbb64191f6",
            "32ce44a56c5849b2862fad237a09ee5f"
          ]
        }
      },
      "source": [
        "for epoch in tnrange(5):\n",
        "    losses = []\n",
        "    for i in range(len(batches)):\n",
        "        batch = batches[i]\n",
        "        triplets = torch.stack(batch)\n",
        "        triplets, labels, nodes, edges = negative_sampling(triplets, n_ent, args.negative_rate)\n",
        "        triplets, labels = triplets.to(args.device), labels.to(args.device)\n",
        "    \n",
        "        model.zero_grad()\n",
        "    \n",
        "        # start = time.time()\n",
        "        model.train()\n",
        "        ent_embed_, rel_embed_ = model(triplets, nodes, edges)\n",
        "        loss = loss_transe(triplets, args.negative_rate, ent_embed_, rel_embed_, device=\"cuda\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "        losses.append(loss.item())\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    print(f\"epoch: {epoch}, loss: {sum(losses) / len(losses)}\")\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d4901b70010492cb0b23006dcfdb02b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 4.453290224075317\n",
            "epoch: 1, loss: 4.449944870812552\n",
            "epoch: 2, loss: 4.4432786873408725\n",
            "epoch: 3, loss: 4.43920510155814\n",
            "epoch: 4, loss: 4.432735817773001\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3nC541cH3Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), \"model.save\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrxC9XIpYGuh",
        "colab_type": "code",
        "outputId": "0c405889-eca0-47d6-8057-915fa95d6af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load(\"model.save\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25Qa-Z6OcwRm",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKG7s9TSlGyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_eval_triplets(triplet: List[torch.Tensor], pos=\"head\", n_ent=14541):\n",
        "    if pos == \"head\":\n",
        "        triplet = torch.tensor([triplet[1].item(), triplet[2].item()])\n",
        "        triplets = triplet.repeat(n_ent).view(-1, 2).t()\n",
        "        triplets = torch.stack((\n",
        "            torch.arange(n_ent),\n",
        "            triplets[0], \n",
        "            triplets[1]\n",
        "        ))\n",
        "    elif pos == \"tail\":\n",
        "        triplet = torch.tensor([triplet[0].item(), triplet[2].item()])\n",
        "        triplets = triplet.repeat(n_ent).view(-1, 2).t()\n",
        "        triplets = torch.stack((\n",
        "            triplets[0], \n",
        "            triplets[1],\n",
        "            torch.arange(n_ent)\n",
        "        ))\n",
        "    \n",
        "    return triplets.t()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMhxjrJiPlF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dl = DataLoader(kg_val, 1, shuffle=True)\n",
        "data = [d for d in dl]\n",
        "triplets = data[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dryKy8K6j0bl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b925174d9145465e81e905c5f4758c14",
            "6cf37ea8c6c74acaa48595d4ed42ef3e",
            "43bb347146154eed98bb448ca7d7de38",
            "d2cf6e5f0bdc4ae3bc7da7f26ba957f0",
            "977b5ee167b14adb8a0a44555103ad40",
            "5855a42937eb43c1986c8f1c9fee6277",
            "590f80f42bd641ffb118fc27fe711633",
            "a20ec3ce32ea4a1fac3db08b77574627"
          ]
        },
        "outputId": "4a5f247f-cb86-4a12-b6fe-6941d39ca270"
      },
      "source": [
        "# n = len(data)\n",
        "n = 1000\n",
        "n_dim = 100\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i in tnrange(n):\n",
        "        # head\n",
        "        triplets = generate_eval_triplets(data[i], \"head\", n_ent)\n",
        "        triplets, labels, nodes, edges = negative_sampling(triplets, n_ent, 0)\n",
        "        triplets, labels = triplets.to(args.device), labels.to(args.device)\n",
        "        ee, re = model(triplets)\n",
        "\n",
        "        dst = ee[data[i][1]].squeeze()\n",
        "        rel = re[data[i][2]].squeeze()\n",
        "        dist = ee + (rel - dst).repeat(n_ent).view(-1, 100)\n",
        "        head_preds = torch.topk(torch.norm(dist, dim=1), k=n_ent)\n",
        "\n",
        "        # tail\n",
        "        triplets = generate_eval_triplets(data[i], \"tail\", n_ent)\n",
        "        triplets, labels, nodes, edges = negative_sampling(triplets, n_ent, 0)\n",
        "        triplets, labels = triplets.to(args.device), labels.to(args.device)\n",
        "        ee, re = model(triplets)\n",
        "\n",
        "        src = ee[data[i][0]].squeeze()\n",
        "        rel = re[data[i][2]].squeeze()\n",
        "        dist = (src + rel).repeat(n_ent).view(-1, 100) - ee\n",
        "        tail_preds = torch.topk(torch.norm(dist, dim=1), k=n_ent)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b925174d9145465e81e905c5f4758c14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-2fd4adb48ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtriplets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegative_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtriplets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mee\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-fe262e741442>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, triplets)\u001b[0m\n\u001b[1;32m     44\u001b[0m         ), dim=1)\n\u001b[1;32m     45\u001b[0m         h_ = torch.cat((\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ment_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ment_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m            \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;31m#   torch.nembedding_renorm_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1484\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_no_grad_embedding_renorm_\u001b[0;34m(weight, input, max_norm, norm_type)\u001b[0m\n\u001b[1;32m   1401\u001b[0m     \u001b[0;31m# type: (Tensor, Tensor, float, float) -> Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: unique: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_9HObonXNMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a51c1ee7-531f-41d8-df1d-b438f3f4de71"
      },
      "source": [
        "torch.norm(dist, dim=0).shape"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmM9GSLjYfW_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a238c7a9-99a3-4eed-b9e0-d3afac63f25e"
      },
      "source": [
        "data[i]"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([749]), tensor([8429]), tensor([68])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMLegcKZS8B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_ = [s.item() for s in triplets[:, 0]]\n",
        "dst_ = [d.item() for d in triplets[:, 1]]\n",
        "rel_ = [r.item() for r in triplets[:, 2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEx6XAIUTV_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src = e[src_]\n",
        "dst = e[dst_]\n",
        "rel = r[rel_]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ajvM7e0T8Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist = pairwise_distances(dst - rel, e, metric=\"euclidean\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blTqpvL-T-6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankArrayHead = np.argsort(dist, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpfIt-eVUAoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankListHead =  [int(np.argwhere(e[1] == e[0])) for e in zip(src_, rankArrayHead)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPgRkoksUDHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "isHit10Head = [x for x in rankListHead if x < 10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD_2hQzXULJ4",
        "colab_type": "code",
        "outputId": "19ec9479-9412-490b-ca01-89fec8bf3e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum(rankListHead) / len(rankListHead)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7254.7366"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsvnpJqdeUfI",
        "colab_type": "code",
        "outputId": "7ac0affa-c62b-4e66-ea70-ac0a3cc73db0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(isHit10Head)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIdTXsb6fBTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist2 = pairwise_distances(src + rel, e, metric=\"euclidean\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrmKgTfBf5Ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankArrayTail = np.argsort(dist2, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_8mtoO4f-5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankListTail = [int(np.argwhere(e[1] == e[0])) for e in zip(dst_, rankArrayTail)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPfbY9DhgILf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "isHit10Tail = [x for x in rankListTail if x < 10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy0vtKO2gQnp",
        "colab_type": "code",
        "outputId": "94733ee1-8621-4f6d-f3b0-b8487ebd6ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(isHit10Tail)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6PjkZvMgVvS",
        "colab_type": "code",
        "outputId": "042869b4-e6f1-49f8-eece-1185f267fdfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum(rankListTail) / len(rankListTail)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7202.4886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KOJgzzphDQi",
        "colab_type": "code",
        "outputId": "24dbe94c-d2c8-42b7-eaaf-7f8a0fe14c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr 17 05:26:53 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    34W / 250W |   2903MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NKXgFTVh4eu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7723f77b-dab5-44df-e8e8-9da19c7e3bbb"
      },
      "source": [
        "kg_val.n_facts"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20466"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF1UwqfJbfBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}